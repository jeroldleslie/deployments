kafka:
  hardware:
    memory: 2gb
    num: 3
  software:
    installation:
      kafka_home_dir: /opt/kafka
      kafka_conf_dir: /opt/kafka/config
      kafka_tgz: kafka_2.10-0.8.2.0.tgz
      kafka_tgz_url: http://jenkinsdp.do.demandcube.com/kafka_2.10-0.8.2.0.tgz
    jvm:
      KAFKA_HEAP_SIZE: 1536
    server_properties:
      zookeeper_clientport: 2181 
      port: 9092
      num_network_threads: 2
      num_io_threads: 8
      socket_send_buffer_bytes: 1048576
      socket_receive_buffer_bytes: 1048576
      socket_request_max_bytes: 104857600
      log_dirs: /opt/kafka/data
      num_partitions: 10
      num_recovery_threads_per_data_dir: 1
      log_retention_hours: 168
      log_retention_bytes: 5000000000
      log_segment_bytes: 536870912
      log_retention_check_interval_ms: 60000
      log_cleaner_enable: 'false'
      zookeeper_connection_timeout_ms: 1000000
      host_name: localhost
      advertised_host_name: <hostname routable by clients>
      advertised_port: <port accessible by clients>
      log_flush_interval_messages: 10000
      log_flush_interval_ms: 1000
    consumer_properties:
      group_id: neverwinterdp
      consumer_zookeeper_connection_timeout_ms: 1000000
      consumer_timeout_ms: 5000
    producer_properties:
      producer_type: async
      compression_codec: none
      serializer_class: kafka.serializer.DefaultEncoder
      partitioner_class: 
      compressed_topics: 
      queue_buffering_max_ms: 
      queue_buffering_max_messages: 
      queue_enqueue_timeout_ms: 
      batch_num_messages:

zookeeper:
  hardware:
    memory: 2gb
    num: 1
  software:
    installation:
      zookeeper_home_dir: /opt/zookeeper
      zookeeper_log_dir: /opt/zookeeper/logs
      zookeeper_data_dir: /opt/zookeeper/data
      zookeeper_clientport: 2181 
      zookeeper_leader_port: 2888
      zookeeper_election_port: 3888
      zookeeper_tar: zookeeper-3.4.6.tar.gz
      zookeeper_url: http://jenkinsdp.do.demandcube.com/zookeeper-3.4.6.tar.gz
    jvm:
      ZOOKEEPER_HEAP_SIZE: 1536
    zoo_cfg:
      tickTime: 2000
      initLimit: 10
      syncLimit: 5
      maxClientCnxns: 60
      autopurge_snapRetainCount: 3
      autopurge_purgeInterval: 1

hadoop_master:
  hardware:
    memory: 2gb
    num: 1
  software:
    installation:
      hadoop_home_dir: /opt/hadoop
      hadoop_tar: hadoop-2.7.1.tar.gz
      hadoop_url: https://archive.apache.org/dist/hadoop/core/hadoop-2.7.1/hadoop-2.7.1.tar.gz
    jvm:
      NAMENODE_HEAPSIZE: 1024
      SECONDARYNAMENODE_HEAPSIZE: 512
      DATANODE_HEAPSIZE: 1024
      YARN_RESOURCEMANAGER_HEAPSIZE: 1024
      YARN_NODEMANAGER_HEAPSIZE: 1024
    core_site:
      hadoop_tmp_dir: /opt/hadoop/data
      fs_default_name: hdfs://hadoop-master:9000
      hadoop_http_staticuser_user: neverwinterdp
    hdfs_site:
      dfs_replication: 3
    yarn_site:
      yarn_resourcemanager_hostname: hadoop-master
      yarn_nodemanager_hostname: 0.0.0.0
      yarn_resourcemanager_scheduler_class: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler

      yarn_nodemanager_resource_cpu_vcores: 4
      yarn_nodemanager_resource_memory_mb: 2048
      yarn_nodemanager_vmem_pmem_ratio: 2
      yarn_nodemanager_vmem_check_enabled: false

      yarn_scheduler_minimum_allocation_mb: 256
      yarn_scheduler_maximum_allocation_mb: 256
      yarn_scheduler_minimum_allocation_vcores: 1
      yarn_scheduler_maximum_allocation_vcores: 1

    capacity_scheduler:
      yarn_scheduler_capacity_resource_calculator: org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator
      
hadoop_worker:
  hardware:
    memory: 2gb
    num: 3
  software:
  
elasticsearch:  
  hardware:
    memory: 2gb
    num: 1
  software:
    installation:
      elasticsearch_home_dir: /opt/elasticsearch

monitoring:
  hardware:
    memory: 2gb
    num: 1
  software:
    installation:
      kibana_url: https://download.elastic.co/kibana/kibana/kibana-4.1.1-linux-x64.tar.gz

