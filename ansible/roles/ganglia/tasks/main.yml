---
- name: Install epel-release
  sudo: yes
  yum: name=epel-release state=installed
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'

- name: install ganglia client (Ubuntu)
  apt: pkg='ganglia-monitor' state=latest
  sudo: yes
  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'  

- name: Install ganglia client (CentOS)
  yum: name='ganglia-gmond' state=installed
  sudo: yes
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'

- name: Install ganglia python plugins (CentOS)
  yum: name='ganglia-gmond-python.x86_64' state=installed
  sudo: yes
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'

- name: Give ganglia user home directory (to support lsof plugin)
  sudo: yes
  lineinfile:  "dest=/etc/passwd state=present  regexp=\"ganglia.*\"  line=\"ganglia:x:998:996:Ganglia Monitoring System:/var/lib/:/bin/bash\""
  
- name: Give ganglia user sudo (to support lsof plugin)
  sudo: yes
  lineinfile:  "dest=/etc/sudoers  state=present line=\"ganglia       ALL=(ALL) NOPASSWD: ALL\""


- name: Make sure crond is installed (CentOS)
  yum: name='cronie' state=installed
  sudo: yes
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'

- name: Check if crond is running (Docker)
  shell: ps -ax | grep crond | grep -v grep | wc -l
  register: crond_running
  when: ansible_virtualization_type == 'docker'

- name: Make sure crond is started (Docker)
  shell: crond
  sudo: yes
  when: ansible_virtualization_type == 'docker' and crond_running.stdout == "0"

- name: Configure gmond (cluster name)
  sudo: yes
  replace: dest=/etc/ganglia/gmond.conf regexp='cluster\s*{\s*name\s*=\s*\"\unspecified\"' replace='cluster {\n  name = "{{ cluster }}"'
  
- name: Configure gmond (ganglia master url)
  sudo: yes
  replace: dest=/etc/ganglia/gmond.conf regexp='udp_send_channel\s*{\s*' replace='udp_send_channel {\n  host = {{ ganglia_url }}\n'
  

- name: Configure gmond (remove multicast)
  sudo: yes
  replace: dest=/etc/ganglia/gmond.conf regexp='.*{{ item }}.*' replace=''
  with_items:
    - mcast_join
    - mcast_join
    - bind\s*=\s*\d*
    - retry_bind
  

- name: Restart ganglia client service (Ubuntu)
  #command: /etc/init.d/ganglia-monitor restart
  service: name=ganglia-monitor state=restarted
  sudo: yes
  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'
  
- name: Restart ganglia client service (CentOS)
  service: name=gmond state=restarted
  sudo: yes
  when: ansible_distribution == 'CentOS' or ansible_distribution == 'Red Hat Enterprise Linux'
  when: ansible_virtualization_type != 'docker'
  

- name: Start gmond manually
  shell: "/usr/sbin/gmond"
  sudo: yes
  when: ansible_virtualization_type == 'docker'

- name: Create ganglia home for custom scripts
  file: path={{ganglia_home}} state=directory mode=0755

- name: Move ganglia plugins to ganglia_home
  copy: src=../plugins/ dest={{ganglia_home}} mode=0755

- name: Move ganglia python plugins
  template: src=../templates/{{ item }}.py.j2  dest=/usr/lib64/ganglia/python_modules/{{ item }}.py
  sudo: yes
  with_items:
    - lsof_counter
  tags:
    - temp

- name: Move ganglia python plugins configs
  template: src=../templates/{{ item }}.pyconf.j2  dest=/etc/ganglia/conf.d/{{ item }}.pyconf
  sudo: yes
  with_items:
    - lsof_counter
  tags:
    - temp

- name: Get current crontab 
  shell: crontab -l
  register: crontab_out
  sudo: yes
  ignore_errors: yes

- name: Write current crontab to temp file
  shell: "printf \"\n{{crontab_out.stdout}}\" > /tmp/cron "
  sudo: yes

- name: Get disk partitions
  shell: cat /proc/partitions | awk '{print $4}' | grep -E "(vda|sda)"
  register: disk_partitions

- name: Add all cronjobs to temp file (non-Docker)
  shell: "echo \"* * * * * $(which perl) {{ganglia_home}}/diskio.pl {{ item }}\" >> /tmp/cron"
  sudo: yes
  with_items:
    - "{{ disk_partitions.stdout_lines }}"


- name: Write cronjob
  shell: crontab /tmp/cron
  sudo: yes

